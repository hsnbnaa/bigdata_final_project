# ğŸ“¦ Pipeline ETL & Analisis Data E-Commerce Olist

![Python](https://img.shields.io/badge/Python-3.x-blue)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Processing-green)
![SQLite](https://img.shields.io/badge/Database-SQLite-lightgrey)
![Status](https://img.shields.io/badge/Status-Completed-success)

Repository ini berisi implementasi **pipeline data end-to-end (ETL & ELT)** untuk memproses, membersihkan, dan menganalisis **dataset E-Commerce**.  
Proyek ini mengubah **data mentah transaksional** menjadi **Data Warehouse berbasis Star Schema** yang siap digunakan untuk analisis bisnis.

---

## ğŸ“Œ Deskripsi Singkat Studi Kasus

Studi kasus menggunakan **Brazilian E-Commerce Public Dataset by Olist**.  
Dataset ini terdiri dari data yang terfragmentasi dalam beberapa tabel, seperti:

- customers  
- orders  
- order_items  
- payments  
- reviews  
- products  

Tujuan utama proyek ini adalah **menyatukan data tersebut ke dalam satu sumber kebenaran (single source of truth)** berupa **Fact Table**, sehingga dapat menjawab pertanyaan bisnis berikut:

- ğŸ“ˆ Tren penjualan bulanan  
- ğŸ›ï¸ Kategori produk terlaris  
- â° Waktu belanja tersibuk  
- ğŸšš Efisiensi ongkos kirim per wilayah  
- ğŸš¨ Deteksi anomali nilai transaksi  

---

## ğŸ—ï¸ Arsitektur Sistem

Pipeline dirancang menggunakan **arsitektur ETL berbasis Python dan SQLite**.

### 1ï¸âƒ£ Extract (Source)
- Data diekstrak dari file **CSV** yang di-hosting di **Google Drive**
- Dataset diunduh langsung melalui URL publik

### 2ï¸âƒ£ Transform (Processing)
Transformasi dilakukan menggunakan **Pandas**, meliputi:

- **Data Cleaning**
  - Standardisasi nama kolom (snake_case)
  - Penghapusan duplikasi data
- **Imputation**
  - Pengisian missing value pada review dan kategori produk
- **Outlier Removal**
  - Menggunakan metode **Interquartile Range (IQR)** pada harga
- **Standardization**
  - MinMax Scaling pada harga dan ongkos kirim
- **Feature Engineering**
  - Ekstraksi fitur waktu (bulan, jam)
  - Label Encoding wilayah
- **Denormalization**
  - Penggabungan tabel menjadi `fact_orders`

### 3ï¸âƒ£ Load (Destination)
- Data bersih dimuat ke **SQLite Database (`olist_dw.db`)**
- Skema yang digunakan: **Star Schema**
  - Fact Table
  - Dimension Tables

### 4ï¸âƒ£ Analytics
- Query analitik dijalankan langsung menggunakan **SQL**
- Digunakan untuk eksplorasi dan pengambilan insight bisnis

---

## ğŸ”„ Perbedaan ETL dan ELT yang Digunakan

Meskipun notebook mencakup keduanya, implementasinya dibedakan secara jelas:

### ğŸ”¹ ETL (Extract â€“ Transform â€“ Load)
**Digunakan sebagai pendekatan utama data engineering**

- Transformasi berat dilakukan **sebelum data masuk ke database**
- Meliputi:
  - Pembersihan outlier
  - Normalisasi (MinMaxScaler)
  - Penggabungan tabel
- Tool utama: **Python (Pandas)**

**Tujuan:**  
Memastikan data yang masuk ke Data Warehouse sudah **bersih, konsisten, dan terstandarisasi**

---

### ğŸ”¹ ELT (Extract â€“ Load â€“ Transform)
**Digunakan pada tahap analytics & reporting**

- Data bersih terlebih dahulu di-load ke SQLite
- Transformasi lanjutan dilakukan **menggunakan SQL**
  - Aggregation (SUM, AVG)
  - Grouping
- Digunakan pada bagian **â€œ8 Query Analitikâ€**

**Tujuan:**  
Memanfaatkan efisiensi **query engine database** untuk analisis data terstruktur

---

## â–¶ï¸ Cara Menjalankan Pipeline (Step-by-Step)

### 1ï¸âƒ£ Persiapan Lingkungan
Pastikan **Python 3.x** sudah terinstal, lalu jalankan:

```bash
pip install pandas numpy scikit-learn
